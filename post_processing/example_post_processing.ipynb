{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This workbook is intended to provide an example of how to process and display the logs from a single session of the Empowerment experiment.  It's not exhausive documentation(!).\n",
    "\n",
    "Original author: Chris Bennett (christopher.bennett@bristol.ac.uk)\n",
    "\n",
    "Last update: 14/06/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files\n",
    "\n",
    "The simulation logs are stored in a direction named with the session id which generated them.  The format of the session id is \"yyyymmddThhmmss\" e.g. \"20220604T151812\".  This is the date and time (in ISO 8601 format) at which the data was collected.\n",
    "\n",
    "The following files should be present in the directory:\n",
    "\n",
    " - **user_details**: stores the participant's responses to questions about themselves e.g. whether english is their first language, date of birth etc.\n",
    " - **post_test_responses**: stores the participant's responses to the questions asked after each trial e.g. \"the sliders\".\n",
    " - **config_fam_X_simlog**: the simulation data (sim_data) from the familiration trials.  \n",
    "     - X is numbered 1-4\n",
    " - **config_exp_X_Y_Z**: the simuulation data (sim_data) from the experimental trials.  \n",
    "     - X is numbered 1-12\n",
    "     - Y is either \n",
    "         - absent  (the simulation did not show the state of the dogs empowerement to the participant during the trial)\n",
    "         - \"empshown\" (empowerment information was shown)\n",
    "     - Z is either\n",
    "         - absent (empowerment was calculated using the \"vanilla\" method where all states in which the dog changes the state of the flock are counted)\n",
    "         - \"taskweighted\" (empowerment was calculated using a method which ones uses states in which the dog effected a change in the flock which moved the flock closer to the goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the environment\n",
    "\n",
    "You will need to edit the paths to match where the simulation logs and empowered_herding program are located\n",
    "\n",
    "Set the session_id to the unique identifier of the experiment you want to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "user_home_dir = os.path.expanduser('~')\n",
    "\n",
    "#change the directory so where the empowered herding model is\n",
    "os.chdir(os.path.join(user_home_dir, 'C:\\\\Users\\\\zi18494\\\\OneDrive - University of Bristol\\\\00_Simulation\\\\Github\\\\empowered_herding'))\n",
    "\n",
    "#change this to the name of the session to be analysed\n",
    "session_id = \"20220614T164059\"\n",
    "\n",
    "#change this to match where the logs are stored\n",
    "#base_path = os.path.join(user_home_dir, \"OneDrive - University of Bristol\\\\00_Simulation\\\\Github\\\\empowered_herding\\\\logs\")\n",
    "base_path = os.path.join(user_home_dir, \"OneDrive - University of Bristol\\\\Empowerment Results\")\n",
    "\n",
    "path = os.path.join(base_path, session_id)\n",
    "\n",
    "#change this to match the name of a single log file of the form config_XXXXXX_simlog.pkl \n",
    "log_file_name = \"config_exp_1_taskweighted_simlog.pkl\"\n",
    "\n",
    "import model.SimLog as log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_of_empowerment(dog_logs, times : list): \n",
    "    import numpy as np\n",
    "    dog_ids = list(dog_logs.keys())\n",
    "    col_names = dog_ids\n",
    "    row_names =  times #list(sim_data['world_at_t'].keys())\n",
    "    #create a big table with 3 dimensions (time, agents, xy-position)\n",
    "    # and initialise it with nan\n",
    "    empowerment_ts = np.empty((len(row_names), len(col_names)))\n",
    "    empowerment_ts[:] = np.nan\n",
    "\n",
    "    #copy the data from the dictionary world_at_t into the big table\n",
    "    for dog_id in dog_logs.keys():\n",
    "        dog_state = dog_logs[dog_id].state\n",
    "        #copy the empowerment\n",
    "        col_idx = np.where(np.asarray(col_names) == dog_id)\n",
    "        row_idx = dog_state['time']\n",
    "        empowerment_ts[row_idx, col_idx] = dog_state['empowerment']\n",
    "    return empowerment_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and display the information about the participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the user responses\n",
    "with open(os.path.join(path,\"user_details.pkl\"), \"rb\") as input_file:\n",
    "    user_details = pickle.load(input_file)\n",
    "#and convert to a pandas dataframe\n",
    "user_details_simple = user_details[1]\n",
    "user_details_simple['english'] = user_details_simple['english'][0][0]\n",
    "user_details_simple['colour'] = user_details_simple['colour'][0][0]\n",
    "user_details_simple['vision'] = user_details_simple['vision'][0][0]\n",
    "user_details_df =  pd.DataFrame(user_details_simple, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the users details\n",
      "---------------------------\n",
      "Session ID was 20220614T164059\n",
      "User details where {'english': 'Yes', 'colour': 'No', 'birth': 'bn', 'sex': 'hgj', 'vision': 'No'}\n",
      "\n",
      "\n",
      "and as a dataframe...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>colour</th>\n",
       "      <th>birth</th>\n",
       "      <th>sex</th>\n",
       "      <th>vision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>bn</td>\n",
       "      <td>hgj</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english colour birth  sex vision\n",
       "0     Yes     No    bn  hgj     No"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"These are the users details\")\n",
    "print(\"---------------------------\")\n",
    "print(f\"Session ID was {user_details[0]}\")\n",
    "print(f\"User details where {user_details[1]}\")\n",
    "print(\"\\n\")\n",
    "print(\"and as a dataframe...\")\n",
    "user_details_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the main processing script which will calculate the metrics and collate the participants responses to each trial into a single pandas data frame with one row per trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test responses by the user\n",
    "with open(os.path.join(path,\"post_test_responses.pkl\"), \"rb\") as input_file:\n",
    "    test_responses = pickle.load(input_file)\n",
    "# extract the parameterised configuration names\n",
    "# IMPORTANT: these names describe each trial that the participant undertook \n",
    "#            and are recorded independently of the simulation logs.\n",
    "config_names = test_responses[1]\n",
    "\n",
    "#convert all the user responses into a pandas dataframe table\n",
    "user_responses_df = pd.DataFrame.from_dict(test_responses[2], orient='index')\n",
    "user_responses_df.attrs = {'session_id': test_responses[0], 'test_order' :  config_names}\n",
    "\n",
    "#find the filenames of all the log files recorded\n",
    "sim_file_names = glob.glob(os.path.join(path,'*_simlog.pkl'))\n",
    "\n",
    "#create some arrays to hold the results\n",
    "n_time_steps = []\n",
    "n_dogs_per_tick = []\n",
    "n_user_interactions = []\n",
    "trial_duration = []\n",
    "distance_2_goal_integral = []\n",
    "trial_start_time = []\n",
    "trial_end_time = []\n",
    "\n",
    "#loop for each parameterised configuration names (these should match the log files in the directory)\n",
    "for i_cfg, cfg_name in enumerate(config_names):\n",
    "    #create a list of all the simulation log files whose file name matchs the paramaterised configuration names\n",
    "    idx = [i for i, s in enumerate(sim_file_names) if (cfg_name + '_simlog') in s]\n",
    "    \n",
    "    #should only return one match, if more than one then skip the file\n",
    "    if len(idx)>1:\n",
    "        print(f'ERROR: found more than one match for {cfg_name} in directory {path}')\n",
    "        n_time_steps.append(-1)\n",
    "        trial_duration.append(-1)\n",
    "        n_user_interactions.append(-1)\n",
    "    #if a file can't be found which matches the tested config name then panic and skip the file\n",
    "    elif not idx:\n",
    "        print(f'ERROR: cant find a match for {cfg_name} in directory {path}')\n",
    "        n_time_steps.append(-1)\n",
    "        trial_duration.append(-1)\n",
    "        n_user_interactions.append(-1)\n",
    "    else:\n",
    "        #if we've made it to here then idx will be a list of one element, change it into an integer to use as an index\n",
    "        idx = idx[0]\n",
    "        with open(sim_file_names[idx], \"rb\") as input_file:\n",
    "             sim_data = pickle.load(input_file)\n",
    "\n",
    "        #calculate the number of dogs present on each time step\n",
    "        n_ts = len(sim_data['world_at_t'].keys())\n",
    "        n_time_steps.append(n_ts)\n",
    "        n_dogs_per_tick = np.zeros(n_ts)\n",
    "        for t in sim_data['world_at_t'].keys():\n",
    "            n_dogs_per_tick[t] = np.sum(sim_data['world_at_t'][t]['ids']<100)\n",
    "            \n",
    "        #extract the empowerment of each dog as a time series and arrange in a table\n",
    "        # columns are the dogs, rows are the time steps, cell values are empowerment\n",
    "        # nan means the dog wasn't present at the corresponding time step\n",
    "        dogs_empowerment_ts = create_table_of_empowerment(sim_data['dog_logs'], list(sim_data['world_at_t'].keys()) )\n",
    "        dog_empowerment_mean = np.nanmean(dogs_empowerment_ts, axis = 1)\n",
    "                                                                       \n",
    "        #calculate the time integral of the distance of the flock CoM from the centre of the square\n",
    "        # The goal position is the same for all configs.  If it wasn't then it could be read by loading the file maching cfg_name\n",
    "        # in experiment_config_files\n",
    "        goal_position = [48,48]\n",
    "        dt = 1\n",
    "        integral = 0\n",
    "        for t in sim_data['world_at_t'].keys():\n",
    "            #agent_positions = sim_data['world_at_t'][t]['positions']\n",
    "            idx_sheep = sim_data['world_at_t'][t]['ids']>=100\n",
    "            sheep_positions = sim_data['world_at_t'][t]['positions'][idx_sheep]\n",
    "            com = np.mean(sheep_positions, axis=0)\n",
    "            distance_2_goal = np.linalg.norm(np.array(goal_position) - com)\n",
    "            integral = integral + distance_2_goal * dt\n",
    "        \n",
    "        distance_2_goal_integral.append(integral)\n",
    "\n",
    "        #calculate the duration of the trial\n",
    "        # this calculation is of trial duration is always the same as n_time_steps????\n",
    "        #    trial_duration.append(np.max(list(sim_data['world_at_t'].keys())))\n",
    "        # so instead, base duration on the real world time difference        \n",
    "        trial_duration.append(sim_data['meta_data']['end_time'] - sim_data['meta_data']['start_time'])\n",
    "        \n",
    "        #calculate number of user interactions (mouse clicks)\n",
    "        n_user_interactions.append(len(sim_data['user_log'].events_at_t.keys()))   \n",
    "        \n",
    "        trial_start_time.append(sim_data['meta_data']['start_time'])\n",
    "        trial_end_time.append(sim_data['meta_data']['end_time'])\n",
    "\n",
    "#this isn't the most efficient but possibly the clearest approach\n",
    "# create a dictionary of the stats and then turn it into a dataframe\n",
    "metrics = {'n_time_steps' : n_time_steps, 'n_user_interactions' : n_user_interactions, 'trial_duration' : trial_duration, \n",
    "           'd2goal_intergral' : distance_2_goal_integral, 'start_time' : trial_start_time, 'end_time' : trial_end_time}       \n",
    "metrics_df =  pd.DataFrame.from_dict(metrics)\n",
    "metrics_df.index = config_names\n",
    "\n",
    "#finally combine the user responses to the slider questions with the metrics from the simulation in a single dataframe\n",
    "test_results_df = pd.concat([user_responses_df, metrics_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the results\n",
      "---------------------------\n",
      "Session ID was 20220614T164059\n",
      "User details where {'english': 'Yes', 'colour': 'No', 'birth': 'bn', 'sex': 'hgj', 'vision': 'No'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>engaged</th>\n",
       "      <th>part_of_team</th>\n",
       "      <th>n_time_steps</th>\n",
       "      <th>n_user_interactions</th>\n",
       "      <th>trial_duration</th>\n",
       "      <th>d2goal_intergral</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>config_exp_2_taskweighted</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0 days 00:00:01.580386</td>\n",
       "      <td>873.423135</td>\n",
       "      <td>2022-06-14 16:41:09.994612</td>\n",
       "      <td>2022-06-14 16:41:11.574998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>config_exp_1_taskweighted</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0 days 00:00:01.840083</td>\n",
       "      <td>1062.267877</td>\n",
       "      <td>2022-06-14 16:41:26.677433</td>\n",
       "      <td>2022-06-14 16:41:28.517516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>config_exp_1_empshown_taskweighted</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0 days 00:00:02.075297</td>\n",
       "      <td>1173.850819</td>\n",
       "      <td>2022-06-14 16:41:39.504239</td>\n",
       "      <td>2022-06-14 16:41:41.579536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>config_exp_2_empshown_taskweighted</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0 days 00:00:02.038569</td>\n",
       "      <td>1136.521848</td>\n",
       "      <td>2022-06-14 16:41:50.205251</td>\n",
       "      <td>2022-06-14 16:41:52.243820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    time  engaged  part_of_team  n_time_steps  \\\n",
       "config_exp_2_taskweighted            1.0        0             0            23   \n",
       "config_exp_1_taskweighted            2.0        1             1            28   \n",
       "config_exp_1_empshown_taskweighted   3.0        2             2            31   \n",
       "config_exp_2_empshown_taskweighted   4.0        3             3            30   \n",
       "\n",
       "                                    n_user_interactions  \\\n",
       "config_exp_2_taskweighted                             3   \n",
       "config_exp_1_taskweighted                             4   \n",
       "config_exp_1_empshown_taskweighted                    4   \n",
       "config_exp_2_empshown_taskweighted                    3   \n",
       "\n",
       "                                           trial_duration  d2goal_intergral  \\\n",
       "config_exp_2_taskweighted          0 days 00:00:01.580386        873.423135   \n",
       "config_exp_1_taskweighted          0 days 00:00:01.840083       1062.267877   \n",
       "config_exp_1_empshown_taskweighted 0 days 00:00:02.075297       1173.850819   \n",
       "config_exp_2_empshown_taskweighted 0 days 00:00:02.038569       1136.521848   \n",
       "\n",
       "                                                   start_time  \\\n",
       "config_exp_2_taskweighted          2022-06-14 16:41:09.994612   \n",
       "config_exp_1_taskweighted          2022-06-14 16:41:26.677433   \n",
       "config_exp_1_empshown_taskweighted 2022-06-14 16:41:39.504239   \n",
       "config_exp_2_empshown_taskweighted 2022-06-14 16:41:50.205251   \n",
       "\n",
       "                                                     end_time  \n",
       "config_exp_2_taskweighted          2022-06-14 16:41:11.574998  \n",
       "config_exp_1_taskweighted          2022-06-14 16:41:28.517516  \n",
       "config_exp_1_empshown_taskweighted 2022-06-14 16:41:41.579536  \n",
       "config_exp_2_empshown_taskweighted 2022-06-14 16:41:52.243820  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"These are the results\")\n",
    "print(\"---------------------------\")\n",
    "print(f\"Session ID was {user_details[0]}\")\n",
    "print(f\"User details where {user_details[1]}\")\n",
    "test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
